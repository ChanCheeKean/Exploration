{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"01 - Basic GAN.ipynb","provenance":[],"collapsed_sections":[]},"coursera":{"schema_names":["GANSC1-1A"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Shl6cLG6fjrU"},"source":["import torch\n","from torch import nn\n","from tqdm.auto import tqdm\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torchvision.utils import make_grid\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JfkorNJrnmNO"},"source":["def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n","    '''\n","    Function for visualizing images: Given a tensor of images, number of images, and\n","    size per image, plots and prints the images in a uniform grid.\n","    '''\n","    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n","    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n","    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1A1M6kpnfxw"},"source":["# Generator"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"EvO7h0LYnEJZ"},"source":["def get_generator_block(input_dim, output_dim):\n","    '''\n","    Function for returning a block of the generator's neural network given input and output dimensions.\n","    '''\n","    return nn.Sequential(\n","        nn.Linear(input_dim, output_dim),\n","        nn.BatchNorm1d(output_dim),\n","        nn.ReLU(inplace=True),\n","    )\n","\n","class Generator(nn.Module):\n","    '''\n","    Generator Class\n","    Values:\n","        z_dim: the dimension of the noise vector, a scalar\n","        im_dim: the dimension of the images, fitted for the dataset used, a scalar (MNIST images are 28 x 28 = 784 so that is your default)\n","        hidden_dim: the inner dimension, a scalar\n","    '''\n","    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(\n","            get_generator_block(z_dim, hidden_dim),\n","            get_generator_block(hidden_dim, hidden_dim * 2),\n","            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n","            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n","            nn.Linear(hidden_dim * 8, im_dim), # (n_samples, im_dim)\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, noise):\n","        return self.gen(noise) # (n_samples, z_dim)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6FLX69EaqRjn"},"source":["# Noise\n","To be able to use your generator, you will need to be able to create noise vectors. The noise vector z has the important role of making sure the images generated from the same class don't all look the same -- think of it as a random seed. \n","\n","Note that whenever you create a new tensor using torch.ones, torch.zeros, or torch.randn, you either need to create it on the target device, e.g. `torch.ones(3, 3, device=device)`, or move it onto the target device using `torch.ones(3, 3).to(device)`. You do not need to do this if you're creating a tensor by manipulating another tensor or by using a variation that defaults the device to the input, such as `torch.ones_like`. In general, use `torch.ones_like` and `torch.zeros_like` instead of `torch.ones` or `torch.zeros` where possible.\n"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"8COwJ9PkqUyd"},"source":["def get_noise(n_samples, z_dim, device='cpu'):\n","    '''\n","    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n","    '''\n","    return torch.randn(n_samples, z_dim, device=device) # (n_samples, z_dim)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9fScH98nkYH"},"source":["# Discriminator\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"sYi8YFcseYFK"},"source":["def get_discriminator_block(input_dim, output_dim):\n","    '''\n","    Function for returning a neural network of the discriminator given input and output dimensions.\n","    '''\n","    return nn.Sequential(\n","         nn.Linear(input_dim, output_dim),\n","         nn.LeakyReLU(0.2, inplace=True)\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aA4AxGnmpuPq"},"source":["class Discriminator(nn.Module):\n","    '''\n","    Discriminator Class\n","    '''\n","    def __init__(self, im_dim=784, hidden_dim=128):\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            get_discriminator_block(im_dim, hidden_dim * 4),\n","            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n","            get_discriminator_block(hidden_dim * 2, hidden_dim),\n","            # final value is single value\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","    def forward(self, image):\n","        '''\n","        Function for completing a forward pass of the discriminator: Given an image tensor (im_dim), \n","        returns a 1-dimension tensor representing fake/real.\n","        '''\n","        return self.disc(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRk_8azSq3tF"},"source":["## Training\n","Now you can put it all together!\n","First, you will set your parameters:\n","  *   criterion: the loss function\n","  *   n_epochs: the number of times you iterate through the entire dataset when training\n","  *   z_dim: the dimension of the noise vector\n","  *   display_step: how often to display/visualize the images\n","  *   batch_size: the number of images per forward/backward pass\n","  *   lr: the learning rate\n","  *   device: the device type, here using a GPU (which runs CUDA), not CPU\n","\n","Next, you will load the MNIST dataset as tensors using a dataloader.\n","\n"]},{"cell_type":"code","metadata":{"id":"IFLQ039u-qdu"},"source":["# Set your parameters\n","criterion = nn.BCEWithLogitsLoss()\n","n_epochs = 200\n","z_dim = 64\n","display_step = 500\n","batch_size = 128\n","lr = 0.00001\n","device = 'cuda'\n","# Load MNIST dataset as tensors\n","dataloader = DataLoader(\n","    MNIST('.', download=True, transform=transforms.ToTensor()),\n","    batch_size=batch_size,\n","    shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDFRZ8tg_Y57"},"source":["gen = Generator(z_dim).to(device)\n","gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n","disc = Discriminator().to(device)\n","disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYzBtiYyz8IJ"},"source":["def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n","    '''\n","    Return the loss of the discriminator given inputs.\n","    '''\n","\n","    # Create noise vectors and generate a batch (num_images) of fake images. \n","    fake_noise = get_noise(num_images, z_dim, device=device)\n","\n","    # Get the discriminator's prediction of the fake image \n","    fake = gen(fake_noise)\n","\n","    # discriminator's prediction of the real image and calculate the loss.\n","    # the ground truth is always zero\n","    disc_fake_pred = disc(fake.detach())\n","    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n","\n","    #  discriminator's prediction of the real image and calculate the loss, ground truth is always one\n","    disc_real_pred = disc(real)\n","    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n","\n","    # Calculate the discriminator's loss by averaging the real and fake loss\n","    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n","\n","    return disc_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zV_8i6y30nTE"},"source":["def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n","    '''\n","    Return the loss of the generator given inputs.\n","    '''\n","    \n","    # Create noise vectors and generate a batch of fake images. \n","    fake_noise = get_noise(num_images, z_dim, device=device)\n","    fake = gen(fake_noise)\n","\n","    # Get the discriminator's prediction of the fake image.\n","    disc_fake_pred = disc(fake)\n","\n","    # Calculate the generator's loss. The generator wants the discriminator to think that its fake images are real\n","    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n","    return gen_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vua5_hRMRb60"},"source":["Finally, you can put everything together! For each epoch, you will process the entire dataset in batches. For every batch, you will need to update the discriminator and generator using their loss. Batches are sets of images that will be predicted on before the loss functions are calculated (instead of calculating the loss function after each image). Note that you may see a loss to be greater than 1, this is okay since binary cross entropy loss can be any positive number for a sufficiently confident wrong guess. \n","\n","It’s also often the case that the discriminator will outperform the generator, especially at the start, because its job is easier. It's important that neither one gets too good (that is, near-perfect accuracy), which would cause the entire model to stop learning. Balancing the two models is actually remarkably hard to do in a standard GAN and something you will see more of in later lectures and assignments.\n","\n","After you've submitted a working version with the original architecture, feel free to play around with the architecture if you want to see how different architectural choices can lead to better or worse GANs. For example, consider changing the size of the hidden dimension, or making the networks shallower or deeper by changing the number of layers.\n","\n","<!-- In addition, be warned that this runs very slowly on a CPU. One way to run this more quickly is to use Google Colab: \n","\n","1.   Download the .ipynb\n","2.   Upload it to Google Drive and open it with Google Colab\n","3.   Make the runtime type GPU (under “Runtime” -> “Change runtime type” -> Select “GPU” from the dropdown)\n","4.   Replace `device = \"cpu\"` with `device = \"cuda\"`\n","5.   Make sure your `get_noise` function uses the right device -->\n","\n","But remember, don’t expect anything spectacular: this is only the first lesson. The results will get better with later lessons as you learn methods to help keep your generator and discriminator at similar levels."]},{"cell_type":"markdown","metadata":{"id":"w3RVHTAvTlod"},"source":["![MNIST Digits](https://raw.githubusercontent.com/amanchadha/coursera-gan-specialization/main/C1%20-%20Build%20Basic%20Generative%20Adversarial%20Networks/Week%201/MNIST_Progression.png)"]},{"cell_type":"code","metadata":{"id":"UXptQZcwrBrq"},"source":["cur_step = 0\n","mean_generator_loss = 0\n","mean_discriminator_loss = 0\n","gen_loss = False\n","error = False\n","\n","for epoch in range(n_epochs):\n","  \n","    # Dataloader returns the batches\n","    for real, _ in tqdm(dataloader):\n","        cur_batch_size = len(real)\n","\n","        # Flatten the batch of real images from the dataset\n","        real = real.view(cur_batch_size, -1).to(device)\n","\n","        ### Update discriminator ###\n","\n","        # Zero out the gradients before backpropagation\n","        disc_opt.zero_grad()\n","\n","        # Calculate discriminator loss\n","        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n","\n","        # Update gradients\n","        disc_loss.backward(retain_graph=True)\n","\n","        # Update optimizer\n","        disc_opt.step()\n","\n","        ### Update generator ###\n","        gen_opt.zero_grad()\n","        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n","        gen_loss.backward()\n","        gen_opt.step()\n","\n","        # Keep track of the average discriminator loss\n","        mean_discriminator_loss += disc_loss.item() / display_step\n","\n","        # Keep track of the average generator loss\n","        mean_generator_loss += gen_loss.item() / display_step\n","\n","        ### Visualization code ###\n","        if cur_step % display_step == 0 and cur_step > 0:\n","            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n","            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n","            fake = gen(fake_noise)\n","            show_tensor_images(fake)\n","            show_tensor_images(real)\n","            mean_generator_loss = 0\n","            mean_discriminator_loss = 0\n","        cur_step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60m4JMmdfGYS"},"source":[""],"execution_count":null,"outputs":[]}]}