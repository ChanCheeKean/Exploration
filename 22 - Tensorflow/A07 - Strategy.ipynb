{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"A07 - Strategy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iv0LmWEOJ96E"},"source":["<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-3-public/blob/main/Course%202%20-%20Custom%20Training%20loops%2C%20Gradients%20and%20Distributed%20Training/Week%204%20-%20Distribution%20Strategy/C2_W4_Lab_1_basic-mirrored-strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"TkUjfmKkflCd"},"source":["import os\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import time\n","import numpy as np\n","tfds.disable_progress_bar()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c_vfnqVSKFWz"},"source":["# Mirror Strategy"]},{"cell_type":"markdown","metadata":{"id":"fhI7y9Y-KV0u"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"id":"eQN-PtIGgFtH"},"source":["# Load the dataset we'll use for this lab\n","datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='./data')\n","mnist_train, mnist_test = datasets['train'], datasets['test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCsDqWnDgNHr","executionInfo":{"status":"ok","timestamp":1619457005543,"user_tz":-480,"elapsed":799,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"9cf3960d-80d1-4905-fd61-e06f1286d63b"},"source":["# Define the strategy to use and print the number of devices found\n","strategy = tf.distribute.MirroredStrategy()\n","print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of devices: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p1xWxKcnhar9"},"source":["# Get the number of examples in the train and test sets\n","num_train_examples = info.splits['train'].num_examples\n","num_test_examples = info.splits['test'].num_examples\n","BUFFER_SIZE = 10000\n","BATCH_SIZE_PER_REPLICA = 64\n","BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPIU8E7BhyYq"},"source":["# Function for normalizing the image\n","def scale(image, label):\n","    image = tf.cast(image, tf.float32)\n","    image /= 255\n","\n","    return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ByTZB2AYh0nA"},"source":["# Set up the train and eval data set\n","train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n","eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rRzY5ojh51B"},"source":["# Use for Mirrored Strategy\n","with strategy.scope():\n","    model = tf.keras.Sequential([\n","      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(64, activation='relu'),\n","      tf.keras.layers.Dense(10)\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWOJWLENphod","executionInfo":{"status":"ok","timestamp":1619457413304,"user_tz":-480,"elapsed":37930,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"be6d7476-4f3c-4c64-9f00-c4a796299544"},"source":["start = time.time()\n","model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n","model.fit(train_dataset, epochs=12)\n","print(\"Time Elapsed:\", time.time() - start)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/12\n","938/938 [==============================] - 5s 3ms/step - loss: 0.4130 - accuracy: 0.8820\n","Epoch 2/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0727 - accuracy: 0.9786\n","Epoch 3/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0509 - accuracy: 0.9849\n","Epoch 4/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0389 - accuracy: 0.9886\n","Epoch 5/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0306 - accuracy: 0.9902\n","Epoch 6/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0223 - accuracy: 0.9936\n","Epoch 7/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0168 - accuracy: 0.9945\n","Epoch 8/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0132 - accuracy: 0.9957\n","Epoch 9/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0114 - accuracy: 0.9959\n","Epoch 10/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0086 - accuracy: 0.9974\n","Epoch 11/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9980\n","Epoch 12/12\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9985\n","Time Elapsed: 37.152125120162964\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-8voqkush_Bx"},"source":["model = tf.keras.Sequential([\n","  tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n","  tf.keras.layers.MaxPooling2D(),\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(64, activation='relu'),\n","  tf.keras.layers.Dense(10)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PveAmmDJLJfC","executionInfo":{"status":"ok","timestamp":1619457338058,"user_tz":-480,"elapsed":28498,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"7793f723-1054-4c4a-fb44-a4be726d4b9d"},"source":["start = time.time()\n","model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n","model.fit(train_dataset, epochs=12)\n","print(time.time() - start)\n","print(\"Time Elapsed:\", time.time() - start)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/12\n","938/938 [==============================] - 3s 2ms/step - loss: 0.4111 - accuracy: 0.8797\n","Epoch 2/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.9795\n","Epoch 3/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0493 - accuracy: 0.9859\n","Epoch 4/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0382 - accuracy: 0.9885\n","Epoch 5/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9916\n","Epoch 6/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0214 - accuracy: 0.9932\n","Epoch 7/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0165 - accuracy: 0.9946\n","Epoch 8/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9966\n","Epoch 9/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - accuracy: 0.9971\n","Epoch 10/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0081 - accuracy: 0.9974\n","Epoch 11/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0069 - accuracy: 0.9979\n","Epoch 12/12\n","938/938 [==============================] - 2s 2ms/step - loss: 0.0042 - accuracy: 0.9989\n","27.78192639350891\n","Time Elapsed: 27.782054662704468\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K2hBsktwLS6K"},"source":["# Multi GPU Mirroed Strategy"]},{"cell_type":"markdown","metadata":{"id":"djf5xwTyLjp_"},"source":["## Set up Environment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"go8E4bArLgwn","executionInfo":{"status":"ok","timestamp":1619457414383,"user_tz":-480,"elapsed":1075,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"b4fad5a0-cce4-40bc-c127-c6cb88ccc9b1"},"source":["# Note that it generally has a minimum of 8 cores, but if your GPU has less, you need to set this. In this case one of my GPUs has 4 cores\n","os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n","\n","# If the list of devices is not specified in the `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n","# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n","strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n","print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of devices: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DGuSLw26LvMh"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"id":"KNAzCI2OLx65"},"source":["# Get the data\n","fashion_mnist = tf.keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# Adding a dimension to the array -> new shape == (28, 28, 1)\n","# it requires a 4D input (batch_size, height, width, channels).\n","train_images = train_images[..., None]\n","test_images = test_images[..., None]\n","\n","# Normalize the images to [0, 1] range.\n","train_images = train_images / np.float32(255)\n","test_images = test_images / np.float32(255)\n","\n","# Batch the input data\n","BUFFER_SIZE = len(train_images)\n","BATCH_SIZE_PER_REPLICA = 64\n","GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n","\n","# Create Datasets from the batches\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n","\n","# Create Distributed Datasets from the datasets\n","train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n","test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WolIkUHFL6ly"},"source":["## Model Building"]},{"cell_type":"code","metadata":{"id":"e-q15o3aL_-M"},"source":["# Create the model architecture\n","def create_model():\n","  model = tf.keras.Sequential([\n","      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(64, activation='relu'),\n","      tf.keras.layers.Dense(10)\n","    ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ejlw0-oMBOd"},"source":["with strategy.scope():\n","    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n","    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n","    # Remember -- the map reduce is how the losses get aggregated\n","    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n","\n","    def compute_loss(labels, predictions):\n","        # Compute Loss uses the loss object to compute the loss\n","        # Notice that per_example_loss will have an entry per GPU\n","        # so in this case there'll be 2 -- i.e. the loss for each replica\n","        per_example_loss = loss_object(labels, predictions)\n","        # You can print it to see it -- you'll get output like this:\n","        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n","        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n","        print(per_example_loss)\n","        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n","\n","    # We'll just reduce by getting the average of the losses\n","    test_loss = tf.keras.metrics.Mean(name='test_loss')\n","\n","    # Accuracy on train and test will be SparseCategoricalAccuracy\n","    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","    # Optimizer will be Adam\n","    optimizer = tf.keras.optimizers.Adam()\n","\n","    # Create the model within the scope\n","    model = create_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOMLEb1ZMDyW"},"source":["# `run` replicates the provided computation and runs it\n","# with the distributed input.\n","@tf.function\n","def distributed_train_step(dataset_inputs):\n","  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n","  #tf.print(per_replica_losses.values)\n","  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n","\n","def train_step(inputs):\n","  images, labels = inputs\n","  with tf.GradientTape() as tape:\n","    predictions = model(images, training=True)\n","    loss = compute_loss(labels, predictions)\n","\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_accuracy.update_state(labels, predictions)\n","  return loss\n","\n","#######################\n","# Test Steps Functions\n","#######################\n","@tf.function\n","def distributed_test_step(dataset_inputs):\n","  return strategy.run(test_step, args=(dataset_inputs,))\n","\n","def test_step(inputs):\n","  images, labels = inputs\n","\n","  predictions = model(images, training=False)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss.update_state(t_loss)\n","  test_accuracy.update_state(labels, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HZuQRMeOMJCV"},"source":["## Model Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gERbAM9DML2t","executionInfo":{"status":"ok","timestamp":1619457581074,"user_tz":-480,"elapsed":47137,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"e8b7c1e1-5596-4c38-9051-296b54793962"},"source":["EPOCHS = 10\n","for epoch in range(EPOCHS):\n","  # Do Training\n","  total_loss = 0.0\n","  num_batches = 0\n","  for batch in train_dist_dataset:\n","    total_loss += distributed_train_step(batch)\n","    num_batches += 1\n","  train_loss = total_loss / num_batches\n","\n","  # Do Testing\n","  for batch in test_dist_dataset:\n","    distributed_test_step(batch)\n","\n","  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n","\n","  print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n","\n","  test_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Epoch 1, Loss: 0.5244734287261963, Accuracy: 80.98833465576172, Test Loss: 0.3979899287223816, Test Accuracy: 85.33999633789062\n","Epoch 2, Loss: 0.34089747071266174, Accuracy: 87.6500015258789, Test Loss: 0.35815730690956116, Test Accuracy: 86.5199966430664\n","Epoch 3, Loss: 0.29265302419662476, Accuracy: 89.50833129882812, Test Loss: 0.29765403270721436, Test Accuracy: 89.29000091552734\n","Epoch 4, Loss: 0.2623736560344696, Accuracy: 90.36166381835938, Test Loss: 0.2956255078315735, Test Accuracy: 89.2300033569336\n","Epoch 5, Loss: 0.24069824814796448, Accuracy: 91.17500305175781, Test Loss: 0.2638099789619446, Test Accuracy: 90.43000030517578\n","Epoch 6, Loss: 0.22031815350055695, Accuracy: 91.90499877929688, Test Loss: 0.26444947719573975, Test Accuracy: 90.20999908447266\n","Epoch 7, Loss: 0.20417606830596924, Accuracy: 92.42500305175781, Test Loss: 0.2520792782306671, Test Accuracy: 90.97999572753906\n","Epoch 8, Loss: 0.1860365867614746, Accuracy: 93.11666870117188, Test Loss: 0.27904194593429565, Test Accuracy: 89.68000030517578\n","Epoch 9, Loss: 0.17221198976039886, Accuracy: 93.6433334350586, Test Loss: 0.24819418787956238, Test Accuracy: 91.15999603271484\n","Epoch 10, Loss: 0.15814147889614105, Accuracy: 94.12166595458984, Test Loss: 0.2518932521343231, Test Accuracy: 91.18000030517578\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QA8E0RyHMOfH"},"source":["# TPU Strategy"]},{"cell_type":"markdown","metadata":{"id":"bIL6VJIRMXBo"},"source":["## Set up"]},{"cell_type":"code","metadata":{"id":"IuXwoVAqMZ41"},"source":["# Detect hardware\n","try:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address) # TPU detection\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu) \n","  # Going back and forth between TPU and host is expensive.\n","  # Better to run 128 batches on the TPU before reporting back.\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","  print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n","except ValueError:\n","  print('TPU failed to initialize.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3S_9nE6zMb_r"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"id":"Dy6n_tP6Mciy"},"source":["SIZE = 224 #@param [\"192\", \"224\", \"331\", \"512\"] {type:\"raw\"}\n","IMAGE_SIZE = [SIZE, SIZE]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHK97bMFMkWq"},"source":["GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-{}x{}/*.tfrec'.format(IMAGE_SIZE[0], IMAGE_SIZE[1])\n","\n","BATCH_SIZE = 128  # On TPU in Keras, this is the per-core batch size. The global batch size is 8x this.\n","\n","VALIDATION_SPLIT = 0.2\n","CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] # do not change, maps to the labels in the data (folder names)\n","\n","# splitting data files between training and validation\n","filenames = tf.io.gfile.glob(GCS_PATTERN)\n","random.shuffle(filenames)\n","\n","split = int(len(filenames) * VALIDATION_SPLIT)\n","training_filenames = filenames[split:]\n","validation_filenames = filenames[:split]\n","print(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\".format(len(filenames), len(training_filenames), len(validation_filenames)))\n","\n","validation_steps = int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n","steps_per_epoch = int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n","print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(BATCH_SIZE, steps_per_epoch, validation_steps))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luLq3ThGMmd9"},"source":["def read_tfrecord(example):\n","    features = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n","        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n","    }\n","    example = tf.io.parse_single_example(example, features)\n","    image = example['image']\n","    class_label = example['class']\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, [224, 224])\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    class_label = tf.cast(class_label, tf.int32)\n","    return image, class_label\n","\n","def load_dataset(filenames):\n","  # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n","  # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n","  # to allow order-altering optimizations.\n","\n","  option_no_order = tf.data.Options()\n","  option_no_order.experimental_deterministic = False\n","\n","  dataset = tf.data.Dataset.from_tensor_slices(filenames)\n","  dataset = dataset.with_options(option_no_order)\n","  dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO) # faster\n","  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n","  return dataset\n","\n","def get_batched_dataset(filenames):\n","  dataset = load_dataset(filenames)\n","  dataset = dataset.shuffle(2048)\n","  dataset = dataset.batch(BATCH_SIZE, drop_remainder=False) # drop_remainder will be needed on TPU\n","  dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","  return dataset\n","\n","def get_training_dataset():\n","  dataset = get_batched_dataset(training_filenames)\n","  dataset = strategy.experimental_distribute_dataset(dataset)\n","  return dataset\n","\n","def get_validation_dataset():\n","  dataset = get_batched_dataset(validation_filenames)\n","  dataset = strategy.experimental_distribute_dataset(dataset)\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7uAOmN27MpNo"},"source":["## Model Building"]},{"cell_type":"code","metadata":{"id":"llrU3FhcMqm5"},"source":["class MyModel(tf.keras.Model):\n","  def __init__(self, classes):\n","    super(MyModel, self).__init__()\n","    self._conv1a = tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same', activation='relu')\n","    self._conv1b = tf.keras.layers.Conv2D(kernel_size=3, filters=30, padding='same', activation='relu')\n","    self._maxpool1 = tf.keras.layers.MaxPooling2D(pool_size=2)\n","    \n","    self._conv2a = tf.keras.layers.Conv2D(kernel_size=3, filters=60, padding='same', activation='relu')\n","    self._maxpool2 = tf.keras.layers.MaxPooling2D(pool_size=2)\n","    \n","    self._conv3a = tf.keras.layers.Conv2D(kernel_size=3, filters=90, padding='same', activation='relu')\n","    self._maxpool3 = tf.keras.layers.MaxPooling2D(pool_size=2)\n","    \n","    self._conv4a = tf.keras.layers.Conv2D(kernel_size=3, filters=110, padding='same', activation='relu')\n","    self._maxpool4 = tf.keras.layers.MaxPooling2D(pool_size=2)\n","    \n","    self._conv5a = tf.keras.layers.Conv2D(kernel_size=3, filters=130, padding='same', activation='relu')\n","    self._conv5b = tf.keras.layers.Conv2D(kernel_size=3, filters=40, padding='same', activation='relu')\n","    \n","    self._pooling = tf.keras.layers.GlobalAveragePooling2D()\n","    self._classifier = tf.keras.layers.Dense(classes, activation='softmax')\n","\n","  def call(self, inputs):\n","    x = self._conv1a(inputs)\n","    x = self._conv1b(x)\n","    x = self._maxpool1(x)\n","\n","    x = self._conv2a(x)\n","    x = self._maxpool2(x)\n","\n","    x = self._conv3a(x)\n","    x = self._maxpool3(x)\n","\n","    x = self._conv4a(x)\n","    x = self._maxpool4(x)\n","\n","    x = self._conv5a(x)\n","    x = self._conv5b(x)\n","\n","    x = self._pooling(x)\n","    x = self._classifier(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AhSO6lb5MsgO"},"source":["## Model Training"]},{"cell_type":"code","metadata":{"id":"QL1pNz1_MvQL"},"source":["with strategy.scope():\n","  model = MyModel(classes=len(CLASSES))\n","  # Set reduction to `none` so we can do the reduction afterwards and divide by global batch size.\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n","\n","  def compute_loss(labels, predictions):\n","    per_example_loss = loss_object(labels, predictions)\n","    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZE * strategy.num_replicas_in_sync)\n","\n","  test_loss = tf.keras.metrics.Mean(name='test_loss')\n","\n","  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","      name='train_accuracy')\n","  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","      name='test_accuracy')\n","  \n","  optimizer = tf.keras.optimizers.Adam()\n","\n","  @tf.function\n","  def distributed_train_step(dataset_inputs):\n","    per_replica_losses = strategy.run(train_step,args=(dataset_inputs,))\n","    print(per_replica_losses)\n","    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n","                           axis=None)\n"," \n","  @tf.function\n","  def distributed_test_step(dataset_inputs):\n","    strategy.run(test_step, args=(dataset_inputs,))\n","\n","\n","  def train_step(inputs):\n","    images, labels = inputs\n","\n","    with tf.GradientTape() as tape:\n","      predictions = model(images)\n","      loss = compute_loss(labels, predictions)\n","\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    train_accuracy.update_state(labels, predictions)\n","\n","    return loss \n","\n","  def test_step(inputs):\n","    images, labels = inputs\n","\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","\n","    test_loss.update_state(loss)\n","    test_accuracy.update_state(labels, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxXVsRnuMw_J"},"source":["EPOCHS = 40\n","with strategy.scope():\n","  for epoch in range(EPOCHS):\n","    # TRAINING LOOP\n","    total_loss = 0.0\n","    num_batches = 0\n","    for x in get_training_dataset():\n","      total_loss += distributed_train_step(x)\n","      num_batches += 1\n","    train_loss = total_loss / num_batches\n","\n","    # TESTING LOOP\n","    for x in get_validation_dataset():\n","      distributed_test_step(x)\n","\n","    template = (\"Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Test Loss: {:.2f}, \"\n","                \"Test Accuracy: {:.2f}\")\n","    print (template.format(epoch+1, train_loss,\n","                           train_accuracy.result()*100, test_loss.result() / strategy.num_replicas_in_sync,\n","                           test_accuracy.result()*100))\n","\n","    test_loss.reset_states()\n","    train_accuracy.reset_states()\n","    test_accuracy.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHy5z40LM0wQ"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"p1D_0HLNNGMt"},"source":["# title display utilities [RUN ME]\n","import matplotlib.pyplot as plt\n","\n","def dataset_to_numpy_util(dataset, N):\n","  dataset = dataset.batch(N)\n","  \n","  if tf.executing_eagerly():\n","    # In eager mode, iterate in the Datset directly.\n","    for images, labels in dataset:\n","      numpy_images = images.numpy()\n","      numpy_labels = labels.numpy()\n","      break;\n","      \n","  else: # In non-eager mode, must get the TF note that \n","        # yields the nextitem and run it in a tf.Session.\n","    get_next_item = dataset.make_one_shot_iterator().get_next()\n","    with tf.Session() as ses:\n","      numpy_images, numpy_labels = ses.run(get_next_item)\n","\n","  return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","  label = np.argmax(label, axis=-1)  # one-hot to class number\n","  # correct_label = np.argmax(correct_label, axis=-1) # one-hot to class number\n","  correct = (label == correct_label)\n","  return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n","                              CLASSES[correct_label] if not correct else ''), correct\n","\n","def display_one_flower(image, title, subplot, red=False):\n","    plt.subplot(subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    plt.title(title, fontsize=16, color='red' if red else 'black')\n","    return subplot+1\n","  \n","def display_9_images_from_dataset(dataset):\n","  subplot=331\n","  plt.figure(figsize=(13,13))\n","  images, labels = dataset_to_numpy_util(dataset, 9)\n","  for i, image in enumerate(images):\n","    title = CLASSES[np.argmax(labels[i], axis=-1)]\n","    subplot = display_one_flower(image, title, subplot)\n","    if i >= 8:\n","      break;\n","              \n","  plt.tight_layout()\n","  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","  plt.show()\n","  \n","def display_9_images_with_predictions(images, predictions, labels):\n","  subplot=331\n","  plt.figure(figsize=(13,13))\n","  for i, image in enumerate(images):\n","    title, correct = title_from_label_and_target(predictions[i], labels[i])\n","    subplot = display_one_flower(image, title, subplot, not correct)\n","    if i >= 8:\n","      break;\n","              \n","  plt.tight_layout()\n","  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","  plt.show()\n","  \n","def display_training_curves(training, validation, title, subplot):\n","  if subplot%10==1: # set up the subplots on the first call\n","    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n","    plt.tight_layout()\n","  ax = plt.subplot(subplot)\n","  ax.set_facecolor('#F8F8F8')\n","  ax.plot(training)\n","  ax.plot(validation)\n","  ax.set_title('model '+ title)\n","  ax.set_ylabel(title)\n","  ax.set_xlabel('epoch')\n","  ax.legend(['train', 'valid.'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtX1146yM4aO"},"source":["inference_model = model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4ekWyOvM57p"},"source":["some_flowers, some_labels = dataset_to_numpy_util(load_dataset(validation_filenames), 8*20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9a2e-5IhM8dm"},"source":["# randomize the input so that you can execute multiple times to change results\n","permutation = np.random.permutation(8*20)\n","some_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n","\n","predictions = inference_model(some_flowers)\n","\n","print(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())\n","\n","display_9_images_with_predictions(some_flowers, predictions, some_labels)"],"execution_count":null,"outputs":[]}]}