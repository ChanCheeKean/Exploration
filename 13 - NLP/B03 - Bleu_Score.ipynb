{"nbformat":4,"nbformat_minor":0,"metadata":{"jupytext":{"encoding":"# -*- coding: utf-8 -*-","formats":"ipynb,py:percent"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"B03 - Bleu_Score.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ONrXJiDxJRTm"},"source":["A popular metric for evaluating the quality of machine-translated text: the BLEU score proposed by Kishore Papineni, et al. In their 2002 paper [\"BLEU: a Method for Automatic Evaluation of Machine Translation\"](https://www.aclweb.org/anthology/P02-1040.pdf), the BLEU score works by comparing \"candidate\" text to one or more \"reference\" translations. The result is better the closer the score is to 1. Let's see how to get this value in the following sections."]},{"cell_type":"markdown","metadata":{"id":"iRn_YauCJRT5"},"source":["# BLEU Score"]},{"cell_type":"code","metadata":{"id":"FPsZuw9XJcF7"},"source":["pip install sacrebleu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"-qbaaYMlJRUZ","executionInfo":{"status":"ok","timestamp":1618668314468,"user_tz":-480,"elapsed":1488,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"338202c6-21f4-48a0-c731-08560a979748"},"source":["import numpy as np                 \n","import nltk                         \n","from nltk.util import ngrams\n","from collections import Counter     \n","import sacrebleu                    \n","import matplotlib.pyplot as plt\n","nltk.download('punkt')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"x5FHoDaXJRUa"},"source":["## Defining the BLEU Score\n","\n","You have seen the formula for calculating the BLEU score in this week's lectures. More formally, we can express the BLEU score as:\n","\n","$$BLEU = BP\\Bigl(\\prod_{i=1}^{4}precision_i\\Bigr)^{(1/4)}$$\n","\n","with the Brevity Penalty and precision defined as:\n","\n","$$BP = min\\Bigl(1, e^{(1-({ref}/{cand}))}\\Bigr)$$\n","\n","$$precision_i = \\frac {\\sum_{snt \\in{cand}}\\sum_{i\\in{snt}}min\\Bigl(m^{i}_{cand}, m^{i}_{ref}\\Bigr)}{w^{i}_{t}}$$\n","\n","where:\n","\n","* $m^{i}_{cand}$, is the count of i-gram in candidate matching the reference translation.\n","* $m^{i}_{ref}$, is the count of i-gram in the reference translation.\n","* $w^{i}_{t}$, is the total number of i-grams in candidate translation."]},{"cell_type":"markdown","metadata":{"id":"K0uJ6NXJJRUb"},"source":["The n-gram precision counts how many unigrams, bigrams, trigrams, and four-grams (i=1,...,4) match their n-gram counterpart in the reference translations. This term acts as a precision metric. Unigrams account for adequacy while longer n-grams account for fluency of the translation. To avoid overcounting, the n-gram counts are clipped to the maximal n-gram count occurring in the reference ($m_{n}^{ref}$). Typically precision shows exponential decay with the with the degree of the n-gram."]},{"cell_type":"markdown","metadata":{"id":"Em5m9iZlJRUb"},"source":["## Calculations of the BLEU score"]},{"cell_type":"code","metadata":{"tags":[],"id":"lC8q0YWZJRUc","executionInfo":{"status":"ok","timestamp":1618668314899,"user_tz":-480,"elapsed":858,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}}},"source":["reference = \"The NASA Opportunity rover is battling a massive dust storm on planet Mars.\"\n","candidate_1 = \"The Opportunity rover is combating a big sandstorm on planet Mars.\"\n","candidate_2 = \"A NASA rover is fighting a massive storm on planet Mars.\"\n","\n","tokenized_ref = nltk.word_tokenize(reference.lower())\n","tokenized_cand_1 = nltk.word_tokenize(candidate_1.lower())\n","tokenized_cand_2 = nltk.word_tokenize(candidate_2.lower())"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4aqjTKoJRUd","executionInfo":{"status":"ok","timestamp":1618668315337,"user_tz":-480,"elapsed":1112,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}}},"source":["def brevity_penalty(reference, candidate):\n","    ref_length = len(reference)\n","    can_length = len(candidate)\n","\n","    # Brevity Penalty by length\n","    if ref_length > can_length:\n","        BP = 1\n","    else:\n","        penalty = 1 - (ref_length / can_length)\n","        BP = np.exp(penalty)\n","    return BP\n","\n","def clipped_precision(reference, candidate):\n","    \"\"\"Bleu score function given a original and a machine translated sentences\"\"\"\n","\n","    clipped_precision_score = []\n","\n","    for i in range(1, 5):\n","        candidate_n_gram = Counter(ngrams(candidate, i)) \n","        reference_n_gram = Counter(ngrams(reference, i)) \n","        # sentence length\n","        c = sum(reference_n_gram.values()) \n","        \n","        # for every pair\n","        for j in reference_n_gram:\n","            if j in candidate_n_gram:\n","                \n","                # compare frequency\n","                if (reference_n_gram[j] > candidate_n_gram[j]): \n","                    reference_n_gram[j] = candidate_n_gram[j]   \n","            else:\n","                reference_n_gram[j] = 0\n","\n","        clipped_precision_score.append(sum(reference_n_gram.values()) / c)\n","\n","    weights = [0.25] * 4\n","\n","    s = (w_i * np.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n","    s = np.exp(np.sum(s))\n","    return s\n","\n","def bleu_score(reference, candidate):\n","    BP = brevity_penalty(reference, candidate)\n","    precision = clipped_precision(reference, candidate)\n","    return BP * precision"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"gRwNYbtGJRUe","executionInfo":{"status":"ok","timestamp":1618668315779,"user_tz":-480,"elapsed":1346,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"e3b1644a-35d5-4e5a-ca9c-fff7e727598f"},"source":["print(\"Results reference versus candidate 1 our own code BLEU: \",\n","      round(bleu_score(tokenized_ref, tokenized_cand_1) * 100, 1))\n","\n","print(\"Results reference versus candidate 2 our own code BLEU: \",\n","      round(bleu_score(tokenized_ref, tokenized_cand_2) * 100, 1))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Results reference versus candidate 1 our own code BLEU:  27.4\n","Results reference versus candidate 2 our own code BLEU:  35.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oN3yrVygJRUp"},"source":["**BLEU Score Interpretation on a Corpus**\n","\n","|Score      | Interpretation                                                |\n","|:---------:|:-------------------------------------------------------------:|\n","| < 10      | Almost useless                                                |\n","| 10 - 19   | Hard to get the gist                                          |\n","| 20 - 29   | The gist is clear, but has significant grammatical errors     |\n","| 30 - 40   | Understandable to good translations                           |\n","| 40 - 50   | High quality translations                                     |\n","| 50 - 60   | Very high quality, adequate, and fluent translations          |\n","| > 60      | Quality often better than human                               |"]},{"cell_type":"code","metadata":{"id":"plJj9vAyJgXj","executionInfo":{"status":"ok","timestamp":1618668315781,"user_tz":-480,"elapsed":764,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}}},"source":[""],"execution_count":10,"outputs":[]}]}